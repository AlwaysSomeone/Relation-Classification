{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from nltk.parse import stanford\n",
    "import nltk, re\n",
    "os.environ['STANFORD_PARSER'] = '/home/shanu/nltk/jars/stanford-parser.jar'\n",
    "os.environ['STANFORD_MODELS'] = '/home/shanu/nltk/jars/stanford-parser-3.7.0-models.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.stanford import StanfordTokenizer\n",
    "path_to_jar = \"/home/shanu/nltk/jars/stanford-postagger.jar\"\n",
    "tokenizer = StanfordTokenizer(path_to_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in open(\"data/TRAIN_FILE.TXT\"):\n",
    "    if line.strip() == \"\" or line.strip().startswith(\"Comment:\"):\n",
    "        if txtfile is not None and annfile is not None:\n",
    "            txtfile.close()\n",
    "            annfile.close()\n",
    "            txtfile = None\n",
    "            annfile = None\n",
    "        continue\n",
    "    m = re.match(r'^([0-9]+)\\s\"(.+)\"$', line.strip())\n",
    "    if m is not None:\n",
    "        txtfile = open(\"train/%s.txt\" % m.group(1), 'w')\n",
    "        annfile = open(\"train/%s.ann\" % m.group(1), 'w')\n",
    "        line = m.group(2)\n",
    "        text = []\n",
    "        t = line.split(\"<e1>\")\n",
    "        text.append(t[0])\n",
    "        e1start = len(t[0])\n",
    "        t = t[1].split(\"</e1>\")\n",
    "        e1 = t[0]\n",
    "        text.append(t[0])\n",
    "        e1end = len(t[0])+e1start\n",
    "        t = t[1].split(\"<e2>\")\n",
    "        text.append(t[0])\n",
    "        e2start = len(t[0])+e1end\n",
    "        t = t[1].split(\"</e2>\")\n",
    "        text.append(t[0])\n",
    "        e2 = t[0]\n",
    "        e2end = len(t[0])+e2start\n",
    "        text.append(t[1])\n",
    "        text = \" \".join(tokenizer.tokenize(\"\".join(text)))\n",
    "        txtfile.write(text)\n",
    "        txtfile.write(\"\\n\")\n",
    "        offset = 0\n",
    "        err = False\n",
    "        while e1 != text[e1start+offset:e1end+offset]:\n",
    "            offset += 1\n",
    "            if e1end+offset > len(text):\n",
    "                break\n",
    "        if e1end+offset > len(text):\n",
    "            offset = 0\n",
    "            e1 = \" \".join(tokenizer.tokenize(e1))\n",
    "            e1end = e1start + len(e1)\n",
    "            while e1 != text[e1start+offset:e1end+offset]:\n",
    "                offset += 1\n",
    "                if e1end+offset > len(text):\n",
    "                    print(\"%d\\t%s\" % (m.group(1), text))\n",
    "                    err = True\n",
    "                    break\n",
    "        if not err:\n",
    "            annfile.write(\"T1\\tTerm %d %d\\t%s\\n\" % (e1start+offset, e1end+offset, e1))\n",
    "        err = False\n",
    "        offset = 0\n",
    "        while e2 != text[e2start+offset:e2end+offset]:\n",
    "            offset+=1\n",
    "            if e2end+offset > len(text):\n",
    "                break\n",
    "        if e2end+offset > len(text):\n",
    "            offset = 0\n",
    "            e2 = \" \".join(tokenizer.tokenize(e2))\n",
    "            e2end = e2start + len(e2)\n",
    "            while e2 != text[e2start+offset:e2end+offset]:\n",
    "                offset += 1\n",
    "                if e2end+offset > len(text):\n",
    "                    print(\"%d\\t%s\" % (m.group(1), text))\n",
    "                    err = True\n",
    "                    break\n",
    "        if not err:\n",
    "            annfile.write(\"T2\\tTerm %d %d\\t%s\\n\" % (e2start+offset, e2end+offset, e2))\n",
    "    else:\n",
    "        reltype = line.strip().split(\"(\")\n",
    "        if len(reltype) < 2:\n",
    "            assert line.strip() == \"Other\", line.strip()\n",
    "            annfile.write(\"R1\\t%s Arg1:T1 Arg2:T2\\n\" % (reltype[0]))\n",
    "        elif reltype[1].startswith(\"e2\"):\n",
    "            annfile.write(\"R1\\t%s Arg1:T2 Arg2:T1\\n\" % (reltype[0]))\n",
    "        else:\n",
    "            annfile.write(\"R1\\t%s Arg1:T1 Arg2:T2\\n\" % (reltype[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
